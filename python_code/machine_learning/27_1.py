"""

지도학습 vs. 비지도학습
레이블 == 정답값 == 결정값 == 타겟값
지도학습은 레이블이 있는 datasets을 가지고 머신러닝 돌리는 것, 비지도학습은 레이블이 없는 datasets 가지고 머신러닝 돌리는 것

sklearn.datasets 내의 모듈 : 사이킷런에서 자체적으로 제공하는 연습 데이터 세트를 생성하는 모듈 모임
sklearn.tree 내의 모듈 : 트리 기반 ML 알고리즘을 구현한 클래스 모임	    cf. 트리 기반의 알고리즘, 경사 기반의 알고리즘이 있다
sklearn.model_selection 내의 모듈 : 학습데이터/검증데이터/예측데이터로 데이터 분리(train_test_split())하거나, 최적의 하이퍼 파라미터로 평가하기 위한 다양한 모듈 모임

train과 test로 분리하는 이유
데이터를 만들고 나면 인공지능한테 학습하라고 던져줄 것. 보통 트리 외의 기반의 알고리즘은 '가중치 학습'(cf. 트리기반 알고리즘은 '트리 학습')이 많다. 
우리는 기계학습 중, 가중치 학습을 위한 데이터로 train데이터만 사용. test데이터는 오직 테스트를 위해서만 사용. 
얼마나 정확한 모델인지 검증할 때 test데이터까지 학습한 뒤, 그 안에서 test데이터 뽑아서 검증한다면? 정답률 100% 나옴 ㅋㅋ

layer와 가중치란?
트리가 아닌 회귀 기반의 알고리즘을 학습할 때 '가중치 학습'을 하는데, 가중치에는 여러 층(layer)이 있다. 
	X→Y 다음 층(layer)으로 넘어갈 때에는 각 개별 요소 x1, x2, x3, x4, ...에 가중치 w1_1, w1_2, w1_3, w2_1, ...를 곱한 값을 다 더한 값이 넘어감. 
	y1 = x1w1_1+x2w2_1+x3w3_1, y2 = x1w2_1+x2w2_2+x3w2_3, .....
	Y→Z는 더 늘어나겠지~~
딥 러닝 : 층이 늘어날 수록 가중치가 기하급수적으로 늘어남. 시간이 오래 걸림(회귀 기법)
회귀 기법 : 오차가 최소가 되는 그래프와 bias를 찾는 것. 

교차 검증 --------- 분할정복이구나~~~~~~~~^0^
train_test_split()해도 test데이터에 과적합(Overfitting모델이 학습 데이터에만 과도하게 최적화)되는 문제가 있다. 
계속 train, predict해서 90%이상 정확도가 나오게 되더라도 사실상 그건 test데이터에 Overfitting되어있을 가능성이 있으므로.
회귀 기반의 overfitting(과적합) : 사실상 1차함수에 가까운 분포였는데, 만약 좌표평면 위의 점들이 딱 들어맞는 4차함수 그래프를 찾아내서 이것을 토대로 예측한다면? 정확도 떨어짐. overfitting. 
	K폴드 교차 검증, Stratified K폴드 교차 검증, cross_val_score
트리 기반의 overfitting(과적합) : 너~~~무 깊이 트리가 만들어질 때 → 예방하려면 파라미터 설정값의 범위를 정해줘야 한다. 안 정해주면 끝까지 파고들어감. 그러면 대부분 overfitting.
	GridSearchCV

K폴드 교차 검증♣
K=5	[               train               ] [   test   ]
	-------------------------------------------
	[_test_][train][train][train][train] [   test   ]
	[train][_test_][train][train][train] [   test   ]
	[train][train][_test_][train][train] [   test   ]
	[train][train][train][_test_][train] [   test   ]
	[train][train][train][train][_test_] [   test   ]
	-------------------------------------------
	[               평균               ] [___test___]
	> 다섯 번의 교차검증의 평균으로 최종 test 검증 (처음부터 끝까지 test인 그 test)

Stratified K폴드 교차 검증♣
특정 레이블 값이 특이하게 많거나 매우 적어서 값의 분포가 한쪽으로 치우칠 때 사용. 
원본 데이터의 유니크한 레이블 값의 분포가 예를 들어 0:1:2 = 10%:30%:60%라고 한다면, 처음 나눈 test데이터를 제외한 전체 train데이터를 K폴드 할 때 그 비율을 맞춰서 K폴드 해줘야 함
또한 예를 들어 0:1:2:3 = 25%:25%:25%:25%인데 섞이지 않고 0,0,0,,,,,0,1,1,1,.,,,,2,2,2,,,,,2,3,,3,,,,3, 이런 경우도 포함
그러면 최종 test데이터가 뭐가 오든 편중된 학습을 하지 않았으니까 좋을 듯~

cross_val_score(estimator, X, y=None, scoring=None, cv=None)♣
교차 검증을 보다 간편하게 해줌
estimator : 사이킷런의 분류 알고리즘 클래스 Classifier의 객체 or 회귀 알고리즘 클래스 Regressor의 객체
	ex_	dt_clf = DecisionTreeClassifier(random_state=156)에서 dt_clf
X : 피처 데이터 세트
y : 레이블 데이터 세트
scoring : 자신이 원하는 판단 기준
	지금까지는 accuracy_score(a, b)로 비교하여 예측 정확도를 판단했지만, 판단 기준에는 accuracy_score만 있는 게 아니다. 
	ex_ 	신용카드를 긁었을 때 1:사기당해서 긁힌 경우, 0:내가 긁은 경우
		사기당했는지 판단하는 프로그램이 멍청해서 무조건 0만 출력한다고 가정. 근데 보통은 사기 아닌 경우(0인 경우)가 99.9999% 
		accuracy_score → 음! 아주 좋은 프로그램이군!
	이럴 땐 다른 판단 기준을 사용해야 한다. 
cv : K값. 몇 개로 split할 것인가. 
n_jobs : 사용 가능한 cpu의 개수

GridSearchCV♣♣♣
cf. 하이퍼 파라미너		-자동으로 설정되는 변수
			-하이퍼 파라미터 튜닝하면 알고리즘 예측 성능 개선할 수 있다. 
결정 트리 알고리즘을 구현한 DecisionTreeClassifier의 하이퍼파라미터를 max_depth=[1,2,3], min_samples_split=[1,2]로 내가 직접 설정한다. 
조합 (1, 2), (1, 3), (2, 2), (2, 3), (3, 2), (3, 3) 6가지가 나온다. 각 설정에 의한 교차 검증(cv=3이라 가정) 하면 각 조합마다 3회에 걸쳐 학습/평가하고 성능을 평균 내서 정확도 최고값 구한다.
이렇게 3x2x3 = 6x3 = 18번의 학습/검증으로 과적합 없이 최적의 결과 내는 파라미터 찾을 수 있다. 

"""
